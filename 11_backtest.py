import os
import pandas as pd
import numpy as np
import json
import torch
import torch.nn as nn
import torch.optim as optim
import math
from sklearn.preprocessing import StandardScaler

# ==========================================
# 1. é…ç½®ä¸å‚æ•°
# ==========================================
DATA_PATH = 'data/finalized/data_with_targets.csv'
PARAMS_PATH = 'models/tuned_models/best_hyperparameters.json'
RESULTS_DIR = 'data/backtest_results'
SEQ_LENGTH = 60

# äº¤æ˜“ç­–ç•¥é…ç½® (ä¼˜åŒ–ç‰ˆ)
INITIAL_CAPITAL = 10000

# å…³é”®ä¿®æ”¹ï¼šå¼•å…¥ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œé˜²æ­¢é•¿æœŸæ¨¡å‹åœ¨ 0.5 é™„è¿‘é¢‘ç¹éœ‡è¡
# åªæœ‰å½“æ¨¡å‹éå¸¸æœ‰ä¿¡å¿ƒæ—¶æ‰äº¤æ˜“
CONFIDENCE_THRESHOLD = 0.05  # 0.5 +/- 0.05 -> Buy > 0.55, Sell < 0.45

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
os.makedirs(RESULTS_DIR, exist_ok=True)

# ==========================================
# 2. æ¨¡å‹å®šä¹‰ (ä¿æŒä¸å˜)
# ==========================================
class LSTMClassifier(nn.Module):
    def __init__(self, input_dim, hidden_dim, num_layers, dropout):
        super(LSTMClassifier, self).__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)
        self.fc = nn.Linear(hidden_dim, 1)
        self.sigmoid = nn.Sigmoid()
    def forward(self, x):
        out, _ = self.lstm(x)
        out = self.fc(out[:, -1, :])
        return self.sigmoid(out)

class GRUClassifier(nn.Module):
    def __init__(self, input_dim, hidden_dim, num_layers, dropout):
        super(GRUClassifier, self).__init__()
        self.gru = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)
        self.fc = nn.Linear(hidden_dim, 1)
        self.sigmoid = nn.Sigmoid()
    def forward(self, x):
        out, _ = self.gru(x)
        out = self.fc(out[:, -1, :])
        return self.sigmoid(out)

class TransformerClassifier(nn.Module):
    def __init__(self, input_dim, d_model, nhead, num_layers, dropout):
        super(TransformerClassifier, self).__init__()
        self.input_embedding = nn.Linear(input_dim, d_model)
        self.pos_encoder = PositionalEncoding(d_model, dropout)
        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward=d_model*2, dropout=dropout, batch_first=True)
        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)
        self.fc = nn.Linear(d_model, 1)
        self.sigmoid = nn.Sigmoid()
    def forward(self, src):
        src = self.input_embedding(src)
        src = self.pos_encoder(src)
        output = self.transformer_encoder(src)
        output = self.fc(output[:, -1, :])
        return self.sigmoid(output)

class PositionalEncoding(nn.Module):
    def __init__(self, d_model, dropout=0.1, max_len=5000):
        super(PositionalEncoding, self).__init__()
        self.dropout = nn.Dropout(p=dropout)
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0)
        self.register_buffer('pe', pe)
    def forward(self, x):
        x = x + self.pe[:, :x.size(1), :]
        return self.dropout(x)

# ==========================================
# 3. è¾…åŠ©å‡½æ•° (å…³é”®ä¿®å¤)
# ==========================================
def create_sequences(data_x, data_y, prices, seq_length):
    xs, ys, ps = [], [], []
    for i in range(len(data_x) - seq_length):
        xs.append(data_x[i:(i + seq_length)])
        ys.append(data_y[i + seq_length])
        ps.append(prices[i + seq_length])
    return np.array(xs), np.array(ys), np.array(ps)

def prepare_data_split(df, ticker, horizon_days):
    """
    ä¿®å¤äº†æ•°æ®æ³„éœ²é—®é¢˜ï¼šå…ˆåˆ’åˆ† Train/Testï¼Œå†è¿›è¡Œ Scaling
    """
    t_df = df[df['Ticker'] == ticker].copy()
    if 'Date' in t_df.columns:
        t_df['Date'] = pd.to_datetime(t_df['Date'])
        t_df = t_df.sort_values('Date')
    
    # ç¡®å®šä»·æ ¼åˆ—
    price_col = 'Close' if 'Close' in t_df.columns else t_df.select_dtypes(include=[np.number]).columns[0]
    
    # ç”Ÿæˆ Target (æ³¨æ„ï¼šæœ€å horizon_days è¡Œçš„ Target æ˜¯ NaNï¼Œéœ€è¦å»æ‰)
    t_df['Target'] = (t_df[price_col].shift(-horizon_days) > t_df[price_col]).astype(float)
    t_df = t_df.dropna(subset=['Target']) # è¿™é‡Œä¼šä¸¢å¼ƒæœ€åå‡ å¤©çš„æ•°æ®
    
    # ç‰¹å¾é€‰æ‹©
    feature_cols = [c for c in t_df.columns if c not in ['Date', 'Ticker', 'Target'] and not c.startswith('target_')]
    numeric_cols = t_df.select_dtypes(include=[np.number]).columns.tolist()
    feature_cols = [c for c in feature_cols if c in numeric_cols]
    
    # æå–åŸå§‹æ•°æ®
    raw_x = t_df[feature_cols].values
    raw_y = t_df['Target'].values
    raw_prices = t_df[price_col].values
    
    # --- å…³é”®ä¿®å¤ï¼šæŒ‰æ—¶é—´åˆ‡åˆ† Train/Test ---
    split_idx = int(len(raw_x) * 0.8)
    
    train_x_raw = raw_x[:split_idx]
    test_x_raw = raw_x[split_idx:]
    
    train_y = raw_y[:split_idx]
    test_y = raw_y[split_idx:]
    
    train_prices = raw_prices[:split_idx]
    test_prices = raw_prices[split_idx:]
    
    # --- å…³é”®ä¿®å¤ï¼šåªåœ¨ Train ä¸Š Fit Scaler ---
    scaler = StandardScaler()
    train_x_scaled = scaler.fit_transform(train_x_raw)
    test_x_scaled = scaler.transform(test_x_raw) # ç”¨è®­ç»ƒé›†çš„å‚æ•°è½¬æ¢æµ‹è¯•é›†
    
    # ç”Ÿæˆåºåˆ—
    X_train, y_train, _ = create_sequences(train_x_scaled, train_y, train_prices, SEQ_LENGTH)
    X_test, y_test, prices_test = create_sequences(test_x_scaled, test_y, test_prices, SEQ_LENGTH)
    
    return X_train, y_train, X_test, y_test, prices_test, len(feature_cols)

def train_and_predict(model_cls, params, input_dim, X_train, y_train, X_test):
    """è®­ç»ƒå¹¶é¢„æµ‹"""
    model_type = params['model_type']
    dropout = params['dropout']
    
    if model_type == 'LSTM':
        model = LSTMClassifier(input_dim, params['lstm_hidden'], params['lstm_layers'], dropout).to(device)
    elif model_type == 'GRU':
        model = GRUClassifier(input_dim, params['gru_hidden'], params['gru_layers'], dropout).to(device)
    elif model_type == 'Transformer':
        d_model = params['nhead'] * params['d_model_mult']
        model = TransformerClassifier(input_dim, d_model, params['nhead'], params['tf_layers'], dropout).to(device)
    
    criterion = nn.BCELoss()
    optimizer = optim.Adam(model.parameters(), lr=params['lr'])
    
    xt = torch.FloatTensor(X_train).to(device)
    yt = torch.FloatTensor(y_train).unsqueeze(1).to(device)
    
    model.train()
    # å¢åŠ  Epochsï¼Œå› ä¸ºç°åœ¨æ•°æ®æ›´â€œçœŸå®éš¾å­¦â€äº†
    epochs = 20 
    for _ in range(epochs):
        optimizer.zero_grad()
        out = model(xt)
        loss = criterion(out, yt)
        loss.backward()
        optimizer.step()
        
    model.eval()
    with torch.no_grad():
        xv = torch.FloatTensor(X_test).to(device)
        preds = model(xv).cpu().numpy().flatten()
        
    return preds

# ==========================================
# 4. ä¸»å›æµ‹å¼•æ“
# ==========================================
def run_backtest_engine():
    print("ğŸš€ Starting Week 11: Backtesting Engine (Fixed Leakage)...")
    
    if not os.path.exists(PARAMS_PATH):
        print("âŒ Best hyperparameters not found.")
        return

    with open(PARAMS_PATH, 'r') as f:
        best_params_registry = json.load(f)
        
    df = pd.read_csv(DATA_PATH)
    results = []
    
    for ticker, horizons in best_params_registry.items():
        for horizon_name, params in horizons.items():
            print(f"\nğŸ”„ Backtesting: {ticker} [{horizon_name}]...")
            
            horizon_days = {'Short': 1, 'Mid': 5, 'Long': 10}.get(horizon_name, 1)
            
            # 1. å‡†å¤‡æ•°æ® (ä½¿ç”¨ä¿®å¤åçš„å‡½æ•°)
            try:
                X_train, y_train, X_test, y_test, prices_test, input_dim = prepare_data_split(df, ticker, horizon_days)
            except ValueError:
                print("   âš ï¸ Not enough data to split.")
                continue

            if len(X_train) < 100 or len(X_test) < 10:
                print("   âš ï¸ Not enough data.")
                continue
                
            # 2. è®­ç»ƒå¹¶é¢„æµ‹
            try:
                probs = train_and_predict(None, params, input_dim, X_train, y_train, X_test)
            except Exception as e:
                print(f"   âŒ Model Error: {e}")
                continue
            
            # 3. æ‰§è¡Œäº¤æ˜“ç­–ç•¥ (åŠ å…¥ç½®ä¿¡åº¦è¿‡æ»¤)
            cash = INITIAL_CAPITAL
            position = 0 
            trades = 0
            
            # åŠ¨æ€è°ƒæ•´é˜ˆå€¼ï¼šLong æ¨¡å‹éœ€è¦æ›´é«˜çš„ç¡®å®šæ€§ï¼Œæˆ–è€…æ›´å®½çš„å®¹é”™
            buy_thresh = 0.50 + CONFIDENCE_THRESHOLD
            sell_thresh = 0.50 - CONFIDENCE_THRESHOLD
            
            for i in range(len(probs) - 1):
                current_price = prices_test[i]
                prob = probs[i]
                
                # åªæœ‰å½“æ¦‚ç‡æ˜¾è‘—åç¦» 0.5 æ—¶æ‰æ“ä½œ
                if prob > buy_thresh and position == 0:
                    position = cash / current_price
                    cash = 0
                    trades += 1
                elif prob < sell_thresh and position > 0:
                    cash = position * current_price
                    position = 0
                    trades += 1
                
            # 4. ç»“ç®—
            final_price = prices_test[-1]
            final_value = cash + (position * final_price)
            roi = (final_value - INITIAL_CAPITAL) / INITIAL_CAPITAL * 100
            
            # è®¡ç®—åŸºå‡†
            initial_price = prices_test[0]
            buy_hold_roi = (final_price - initial_price) / initial_price * 100
            
            # è®¡ç®—èƒœç‡ (æ–¹å‘é¢„æµ‹å‡†ç¡®ç‡)
            # å°†æ¦‚ç‡è½¬ä¸º 0/1 é¢„æµ‹
            pred_dirs = (probs > 0.5).astype(float)
            accuracy = (pred_dirs == y_test).mean() * 100
            
            print(f"   ğŸ’° Final: ${final_value:.2f} | ROI: {roi:.2f}% | Trades: {trades}")
            print(f"   ğŸ¯ Win Rate (Accuracy): {accuracy:.2f}%")
            
            results.append({
                'Ticker': ticker,
                'Horizon': horizon_name,
                'Model': params['model_type'],
                'ROI': roi,
                'Buy_Hold_ROI': buy_hold_roi,
                'Trades': trades,
                'Win_Rate': f"{accuracy:.1f}%"
            })

    res_df = pd.DataFrame(results)
    save_path = os.path.join(RESULTS_DIR, 'backtest_summary.csv')
    res_df.to_csv(save_path, index=False)
    
    if not res_df.empty:
        print("\n" + "="*60)
        # æ ¼å¼åŒ–è¾“å‡ºï¼Œæ–¹ä¾¿æŸ¥çœ‹
        print(res_df[['Ticker', 'Horizon', 'Model', 'ROI', 'Buy_Hold_ROI', 'Trades', 'Win_Rate']].to_string(index=False))

if __name__ == "__main__":
    run_backtest_engine()




























































    