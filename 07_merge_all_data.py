import pandas as pd
import os
from pathlib import Path

# --- é…ç½®è·¯å¾„ ---
DATA_DIR = Path('data')
RAW_DIR = DATA_DIR / 'raw'
PROCESSED_DIR = DATA_DIR / 'processed'
FINAL_DIR = DATA_DIR / 'finalized'

# è¾“å‡ºæ–‡ä»¶
OUTPUT_FILE = FINAL_DIR / 'final_master_dataset.csv'

def standardize_columns(df, source_name="Unknown"):
    """
    ç»Ÿä¸€åˆ—åï¼Œå¤„ç†å¤§å°å†™é—®é¢˜ã€‚
    """
    # 0. å»é™¤åˆ—åä¸¤ç«¯çš„ç©ºæ ¼
    df.columns = [str(c).strip() for c in df.columns]

    # 1. å°è¯•è¯†åˆ«å„ç§å˜ä½“çš„ Date
    if 'Date' not in df.columns:
        for col in df.columns:
            if col.lower() in ['date', 'time', 'timestamp', 'datetime']:
                print(f"  -> åœ¨ {source_name} ä¸­å°† '{col}' é‡å‘½åä¸º 'Date'")
                df.rename(columns={col: 'Date'}, inplace=True)
                break
    
    # 2. è§£å†³ ticker -> Ticker (è¿™æ˜¯ä½ ä¹‹å‰é‡åˆ°é—®é¢˜çš„å…³é”®)
    if 'Ticker' not in df.columns:
        for col in df.columns:
            if col.lower() in ['ticker', 'symbol', 'code']:
                print(f"  -> åœ¨ {source_name} ä¸­å°† '{col}' é‡å‘½åä¸º 'Ticker'")
                df.rename(columns={col: 'Ticker'}, inplace=True)
                break
    
    # 3. ç¡®ä¿ Date æ˜¯ datetime ç±»å‹
    if 'Date' in df.columns:
        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
        
    return df

def load_price_data():
    """åŠ è½½ä»·æ ¼/æŠ€æœ¯æŒ‡æ ‡æ•°æ®"""
    potential_files = [
        DATA_DIR / 'features_technical.csv', 
        DATA_DIR / 'processed' / 'technical_indicators.csv'
    ]
    
    target_file = None
    for f in potential_files:
        if f.exists():
            target_file = f
            break
            
    if target_file:
        print(f"âœ… æ‰¾åˆ°ä»·æ ¼/ç‰¹å¾æ•°æ®: {target_file}")
        df = pd.read_csv(target_file)
        df = standardize_columns(df, "Price Data")
        return df
    return None

def load_sentiment_data():
    sent_file = PROCESSED_DIR / 'sentiment_scores.csv'
    if not sent_file.exists():
        return None
    
    print(f"âœ… åŠ è½½æƒ…æ„Ÿæ•°æ®: {sent_file}")
    df = pd.read_csv(sent_file)
    df = standardize_columns(df, "Sentiment Data")
    return df

def load_fundamental_data():
    fund_file = RAW_DIR / 'fundamentals.csv' 
    if not fund_file.exists():
        print(f"âš ï¸ è­¦å‘Š: æ‰¾ä¸åˆ°åŸºæœ¬é¢æ•°æ® {fund_file}")
        return None

    print(f"âœ… åŠ è½½åŸºæœ¬é¢æ•°æ®: {fund_file}")
    try:
        df = pd.read_csv(fund_file)
        df = standardize_columns(df, "Fundamental Data")
        
        # ç­›é€‰ä¸€äº›æœ‰ç”¨çš„åˆ—ï¼Œé˜²æ­¢æ•°æ®è¡¨è¿‡å¤§åŒ…å«æ— ç”¨ä¿¡æ¯ï¼ˆå¦‚åœ°å€ã€ç”µè¯ç­‰ï¼‰
        # å¦‚æœä½ æƒ³ä¿ç•™æ‰€æœ‰åˆ—ï¼Œå¯ä»¥æ³¨é‡Šæ‰ä¸‹é¢è¿™æ®µ
        useful_keywords = [
            'Ticker', 'Date', 'sector', 'industry', 'marketCap', 'trailingPE', 
            'forwardPE', 'bookValue', 'priceToBook', 'trailingEps', 'forwardEps',
            'beta', 'fiftyTwoWeekHigh', 'fiftyTwoWeekLow', 'averageVolume',
            'profitMargins', 'revenueGrowth', 'operatingMargins'
        ]
        # æ‰¾å‡ºdfä¸­å­˜åœ¨çš„ä¸”åŒ…å«åœ¨useful_keywordsé‡Œçš„åˆ—ï¼Œæˆ–è€…æ˜¯Ticker/Date
        cols_to_keep = [c for c in df.columns if c in useful_keywords or c in ['Ticker', 'Date']]
        
        # å¦‚æœç­›é€‰ååˆ—å¤ªå°‘ï¼ˆè¯´æ˜åˆ—åå¯èƒ½ä¸åŒ¹é…ï¼‰ï¼Œå°±ä¿ç•™æ‰€æœ‰æ•°å€¼å‹åˆ—
        if len(cols_to_keep) < 3:
            print("  -> æœªèƒ½è‡ªåŠ¨ç­›é€‰æ ¸å¿ƒåŸºæœ¬é¢åˆ—ï¼Œå°†ä¿ç•™æ‰€æœ‰åˆ—ã€‚")
        else:
            print(f"  -> ç­›é€‰å‡º {len(cols_to_keep)} ä¸ªæ ¸å¿ƒåŸºæœ¬é¢ç‰¹å¾ã€‚")
            df = df[cols_to_keep]

        return df
    except Exception as e:
        print(f"âŒ è¯»å–åŸºæœ¬é¢æ•°æ®å¤±è´¥: {e}")
        return None

def merge_datasets():
    print("--- å¼€å§‹æ•°æ®åˆå¹¶ (Data Integration) ---")
    os.makedirs(FINAL_DIR, exist_ok=True)

    # 1. åŠ è½½ä¸»æ•°æ®
    df_main = load_price_data()
    if df_main is None: 
        print("âŒ æ— æ³•æ‰¾åˆ°ä¸»ä»·æ ¼æ•°æ®ï¼Œç¨‹åºç»ˆæ­¢ã€‚")
        return
    
    # 2. åˆå¹¶æƒ…æ„Ÿæ•°æ®
    df_sent = load_sentiment_data()
    if df_sent is not None:
        merge_cols = ['Date']
        if 'Ticker' in df_sent.columns and 'Ticker' in df_main.columns:
            merge_cols = ['Date', 'Ticker']
        
        print(f"æ­£åœ¨åˆå¹¶æƒ…æ„Ÿæ•°æ® (Keys: {merge_cols})...")
        df_main = pd.merge(df_main, df_sent, on=merge_cols, how='left')
        if 'Sentiment_Score' in df_main.columns:
            df_main['Sentiment_Score'] = df_main['Sentiment_Score'].fillna(0)

    # 3. åˆå¹¶åŸºæœ¬é¢æ•°æ® (ä¿®å¤ç‰ˆé€»è¾‘)
    df_fund = load_fundamental_data()
    
    if df_fund is not None:
        if 'Ticker' in df_fund.columns:
            # åˆ¤æ–­åˆå¹¶ç­–ç•¥
            if 'Date' in df_fund.columns:
                print("â„¹ï¸ æ£€æµ‹åˆ°å†å²åŸºæœ¬é¢æ•°æ® (å« Date)ï¼Œæ‰§è¡Œ [Date, Ticker] ç²¾ç¡®åˆå¹¶...")
                df_main['Date'] = pd.to_datetime(df_main['Date'])
                df_fund['Date'] = pd.to_datetime(df_fund['Date'])
                df_main = pd.merge(df_main, df_fund, on=['Date', 'Ticker'], how='left')
                # å†å²æ•°æ®é€šå¸¸éœ€è¦å‘ä¸‹å¡«å…… (ffill)
                df_main.groupby('Ticker').ffill(inplace=True)
            else:
                print("â„¹ï¸ æ£€æµ‹åˆ°é™æ€åŸºæœ¬é¢æ•°æ® (æ—  Date)ï¼Œæ‰§è¡Œ [Ticker] å¹¿æ’­åˆå¹¶...")
                # è¿™ç§åˆå¹¶ä¼šå°†åŸºæœ¬é¢ä¿¡æ¯å¤åˆ¶åˆ°è¯¥ Ticker çš„æ¯ä¸€è¡Œ
                df_main = pd.merge(df_main, df_fund, on=['Ticker'], how='left')
        else:
            print("âš ï¸ åŸºæœ¬é¢æ•°æ®ç¼ºå°‘ 'Ticker' åˆ—ï¼Œæ— æ³•åˆå¹¶ã€‚")
    else:
        print("â„¹ï¸ æœ¬æ¬¡è¿è¡ŒæœªåŒ…å«åŸºæœ¬é¢æ•°æ®ã€‚")

    # 4. ç”Ÿæˆç›®æ ‡å˜é‡
    if 'target_5d_return' not in df_main.columns:
        print("â„¹ï¸ è®¡ç®—ç›®æ ‡å˜é‡: target_5d_return")
        df_main.sort_values(['Ticker', 'Date'], inplace=True)
        # ç¡®ä¿ Close æ˜¯æ•°å€¼å‹
        df_main['Close'] = pd.to_numeric(df_main['Close'], errors='coerce')
        df_main['target_5d_return'] = df_main.groupby('Ticker')['Close'].transform(lambda x: x.shift(-5) / x - 1)

    # 5. æ¸…æ´—
    initial_len = len(df_main)
    df_main.dropna(subset=['target_5d_return'], inplace=True) 
    
    # å¡«å……ç¼ºå¤±å€¼ï¼ˆæ•°å€¼å‹å¡«0ï¼Œéæ•°å€¼å‹å¡«Unknownï¼‰
    num_cols = df_main.select_dtypes(include=['number']).columns
    df_main[num_cols] = df_main[num_cols].fillna(0)
    
    print(f"åˆå¹¶å®Œæˆã€‚åŸå§‹è¡Œæ•°: {initial_len}, æ¸…æ´—åè¡Œæ•°: {len(df_main)}")
    
    # 6. ä¿å­˜
    df_main.to_csv(OUTPUT_FILE, index=False)
    print(f"ğŸ‰ æœ€ç»ˆä¸»æ•°æ®é›†å·²ä¿å­˜è‡³: {OUTPUT_FILE}")

if __name__ == "__main__":
    merge_datasets()