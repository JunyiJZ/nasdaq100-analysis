import pandas as pd
import numpy as np
import os
import json
import time
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

# ==========================================
# 1. é…ç½®ä¸Žè¾…åŠ©å‡½æ•°
# ==========================================
# ä¸ºäº†èŠ‚çœæ—¶é—´ï¼Œæ¼”ç¤ºæ—¶æˆ‘ä»¬åªé€‰å‰ 3 ä¸ªè‚¡ç¥¨è¿›è¡Œå¯¹æ¯”æŠ¥å‘Š
# å¦‚æžœä½ æƒ³è·‘å…¨é‡ï¼ŒæŠŠè¿™ä¸ªåˆ—è¡¨è®¾ä¸º None
TEST_TICKERS = ['AAPL', 'MSFT', 'GOOGL'] 

def prepare_data(df, ticker, horizon_days, look_back=60):
    # (è¿™é‡Œç›´æŽ¥å¤ç”¨ä¹‹å‰çš„ä»£ç ï¼Œä¿æŒä¸€è‡´æ€§)
    data = df[df['Ticker'] == ticker].copy()
    if len(data) == 0: return None, None, None, None, None
    if 'Date' in data.columns:
        data['Date'] = pd.to_datetime(data['Date'])
        data = data.sort_values('Date')
    
    feature_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'RSI_14', 'MACD_12_26_9', 'MACDs_12_26_9']
    data['Target'] = (data['Close'].shift(-horizon_days) > data['Close']).astype(int)
    data = data[feature_cols + ['Target']].dropna()
    if len(data) == 0: return None, None, None, None, None

    scaler = MinMaxScaler()
    scaled_data = scaler.fit_transform(data[feature_cols]) 

    X, y = [], []
    for i in range(look_back, len(scaled_data)):
        X.append(scaled_data[i-look_back:i])
        y.append(data['Target'].iloc[i])
    X, y = np.array(X), np.array(y)
    
    if len(X) < 100: return None, None, None, None, None # æ•°æ®å¤ªå°‘è·³è¿‡

    split = int(len(X) * 0.8)
    return X[:split], y[:split], X[split:], y[split:], scaler

# ==========================================
# 2. æž„å»ºæ¨¡åž‹å‡½æ•°
# ==========================================

# A. é»˜è®¤æ¨¡åž‹ (Untuned / Baseline)
# è¿™æ˜¯ä¸€ä¸ªâ€œå‡­æ„Ÿè§‰â€è®¾ç½®çš„æ™®é€šæ¨¡åž‹ï¼Œç”¨æ¥åšå¯¹æ¯”åŸºå‡†
def build_untuned_model(input_shape):
    model = Sequential()
    model.add(LSTM(50, return_sequences=False, input_shape=input_shape)) # é»˜è®¤50ä¸ªå•å…ƒ
    model.add(Dropout(0.2)) # é»˜è®¤0.2
    model.add(Dense(1, activation='sigmoid'))
    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])
    return model

# B. è°ƒä¼˜åŽçš„æ¨¡åž‹ (Tuned)
# ä»Ž JSON è¯»å–æœ€ä½³å‚æ•°
def build_tuned_model(params, input_shape):
    model = Sequential()
    model.add(LSTM(units=params['units_1'], return_sequences=params['return_sequences'], input_shape=input_shape))
    model.add(Dropout(params['dropout_1']))
    if params['return_sequences']:
        model.add(LSTM(units=params['units_2'], return_sequences=False))
        model.add(Dropout(params['dropout_2']))
    model.add(Dense(1, activation='sigmoid'))
    model.compile(optimizer=Adam(learning_rate=params['learning_rate']), loss='binary_crossentropy', metrics=['accuracy'])
    return model

# ==========================================
# 3. ä¸»å¯¹æ¯”æµç¨‹
# ==========================================
def evaluate_gains():
    # è·¯å¾„è®¾ç½®
    base_dir = os.getcwd()
    data_path = os.path.join(base_dir, 'data', 'finalized', 'final_master_dataset.csv')
    params_path = os.path.join(base_dir, 'data', 'tuned_models', 'best_hyperparameters.json')
    
    if not os.path.exists(params_path):
        print("âŒ æ‰¾ä¸åˆ°æœ€ä½³å‚æ•°æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œ Step 10ï¼")
        return

    print("æ­£åœ¨è¯»å–æ•°æ®...")
    df = pd.read_csv(data_path)
    with open(params_path, 'r') as f:
        best_params_record = json.load(f)

    results = []

    # éåŽ† JSON é‡Œè®°å½•çš„æ¯ä¸€ä¸ª (Ticker + Horizon)
    for key, record in best_params_record.items():
        parts = key.split('_')
        horizon_name = parts[-1]
        ticker = "_".join(parts[:-1])
        
        # å¦‚æžœè®¾ç½®äº†æµ‹è¯•åˆ—è¡¨ï¼Œä¸”è¯¥è‚¡ç¥¨ä¸åœ¨åˆ—è¡¨é‡Œï¼Œè·³è¿‡ï¼ˆä¸ºäº†å¿«é€Ÿç”ŸæˆæŠ¥å‘Šï¼‰
        if TEST_TICKERS and ticker not in TEST_TICKERS:
            continue

        horizon_map = {'Short': 1, 'Medium': 5, 'Long': 20}
        horizon_days = horizon_map.get(horizon_name, 1)

        print(f"\nðŸ“Š æ­£åœ¨å¯¹æ¯”: {ticker} - {horizon_name} ...")

        # 1. å‡†å¤‡æ•°æ®
        X_train, y_train, X_test, y_test, _ = prepare_data(df, ticker, horizon_days)
        if X_train is None: continue

        # --- è·‘é»˜è®¤æ¨¡åž‹ (Untuned) ---
        start_time = time.time()
        model_untuned = build_untuned_model((X_train.shape[1], X_train.shape[2]))
        # ç®€å•è®­ç»ƒ 10 ä¸ª epoch çœ‹æ•ˆæžœ
        hist_untuned = model_untuned.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15, batch_size=32, verbose=0)
        time_untuned = time.time() - start_time
        acc_untuned = max(hist_untuned.history['val_accuracy']) # å–éªŒè¯é›†æœ€ä½³ç²¾åº¦

        # --- è·‘è°ƒä¼˜æ¨¡åž‹ (Tuned) ---
        start_time = time.time()
        model_tuned = build_tuned_model(record['best_params'], (X_train.shape[1], X_train.shape[2]))
        hist_tuned = model_tuned.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15, batch_size=32, verbose=0)
        time_tuned = time.time() - start_time
        acc_tuned = max(hist_tuned.history['val_accuracy'])

        # --- è®¡ç®—æå‡ ---
        gain = acc_tuned - acc_untuned
        print(f"   ðŸ”¹ é»˜è®¤ç²¾åº¦: {acc_untuned:.4f} (è€—æ—¶ {time_untuned:.1f}s)")
        print(f"   ðŸ”¸ è°ƒä¼˜ç²¾åº¦: {acc_tuned:.4f} (è€—æ—¶ {time_tuned:.1f}s)")
        print(f"   ðŸš€ æå‡: {gain*100:.2f}%")

        results.append({
            'Ticker': ticker,
            'Horizon': horizon_name,
            'Untuned_Acc': acc_untuned,
            'Tuned_Acc': acc_tuned,
            'Gain': gain,
            'Untuned_Time': time_untuned,
            'Tuned_Time': time_tuned
        })

    # ==========================================
    # 4. ç”ŸæˆæŠ¥å‘Š
    # ==========================================
    if results:
        res_df = pd.DataFrame(results)
        report_path = os.path.join(base_dir, 'data', 'tuned_models', 'performance_comparison.csv')
        res_df.to_csv(report_path, index=False)
        print(f"\nâœ… å¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        
        # ç®€å•æ‰“å°å¹³å‡æå‡
        avg_gain = res_df['Gain'].mean()
        print(f"\nðŸ† å¹³å‡å‡†ç¡®çŽ‡æå‡: {avg_gain*100:.2f}%")
        print("ðŸ’¡ æç¤ºï¼šå¦‚æžœæå‡ä¸ºè´Ÿï¼Œè¯´æ˜Žé»˜è®¤å‚æ•°è¿æ°”å¥½ï¼Œæˆ–è€…è°ƒä¼˜æ¬¡æ•°(n_trials)è¿˜ä¸å¤Ÿå¤šã€‚")

if __name__ == "__main__":
    evaluate_gains()